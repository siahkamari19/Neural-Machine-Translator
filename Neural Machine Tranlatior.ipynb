{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Neural Machine Tranlatior.ipynb","provenance":[{"file_id":"1xBT0-It0Xis-2NfA1K5vTxKM8CDiS8p5","timestamp":1619706510733}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"lVgRIXKwmAtS"},"source":["from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n","from keras.layers import RepeatVector, Dense, Activation, Lambda\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.models import load_model, Model\n","import keras.backend as K\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5E3rvx6maoo","executionInfo":{"status":"ok","timestamp":1619705653576,"user_tz":240,"elapsed":5527,"user":{"displayName":"Mohammad Siahkamari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh93O-ww1g1fVMNubHBRdJ2afL6y-wMM9gAkLCf43U=s64","userId":"17116706248704947141"}},"outputId":"ff8b00eb-06ce-4cde-f33b-d42579e59522"},"source":["!pip install Faker\n","\n","from faker import Faker\n","import random\n","from tqdm import tqdm\n","from babel.dates import format_date\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","fake = Faker()\n","Faker.seed(12345)\n","random.seed(12345)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting Faker\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/dc/266528ca3f7e6c14016832b955adc4313b9c18529a5012e13c42b858c33f/Faker-8.1.1-py3-none-any.whl (1.2MB)\n","\r\u001b[K     |▎                               | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 13.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 15.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 16.2MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 81kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 18.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 102kB 16.6MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 122kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 133kB 16.6MB/s eta 0:00:01\r\u001b[K     |████                            | 143kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 153kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 163kB 16.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 174kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 194kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 204kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 215kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 225kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 235kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 245kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 256kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 266kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 276kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 286kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 296kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 307kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 317kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 327kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 337kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 348kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 358kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 368kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 378kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 389kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 399kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 409kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 419kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 430kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 440kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 450kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 460kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 471kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 481kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 491kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 501kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 512kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 522kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 532kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 542kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 552kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 563kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 573kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 583kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 593kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 604kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 614kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 624kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 634kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 645kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 655kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 665kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 675kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 686kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 696kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 706kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 716kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 727kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 737kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 747kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 757kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 768kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 778kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 788kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 798kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 808kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 819kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 829kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 839kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 849kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 860kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 870kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 880kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 890kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 901kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 911kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 921kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 931kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 942kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 952kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 962kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 972kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 983kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 993kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.0MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.2MB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 16.6MB/s \n","\u001b[?25hRequirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from Faker) (1.3)\n","Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from Faker) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->Faker) (1.15.0)\n","Installing collected packages: Faker\n","Successfully installed Faker-8.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5rgKWgxUvnn9"},"source":["# Define format of the data we would like to generate\n","FORMATS = ['short',\n","           'medium',\n","           'long',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'full',\n","           'd MMM YYY', \n","           'd MMMM YYY',\n","           'dd MMM YYY',\n","           'd MMM, YYY',\n","           'd MMMM, YYY',\n","           'dd, MMM YYY',\n","           'd MM YY',\n","           'd MMMM YYY',\n","           'MMMM d YYY',\n","           'MMMM d, YYY',\n","           'dd.MM.YY']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k7Em6s5JtY__"},"source":["def load_dataset(m):\n","    human_vocab = set()\n","    machine_vocab = set()\n","    dataset = []\n","    Tx = 30\n","    \n","    for i in tqdm(range(m)):\n","        h, m, _ = load_date()\n","        if h is not None:\n","            dataset.append((h, m))\n","            human_vocab.update(tuple(h))\n","            machine_vocab.update(tuple(m))\n","    \n","    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'], \n","                     list(range(len(human_vocab) + 2))))\n","    inv_machine = dict(enumerate(sorted(machine_vocab)))\n","    machine = {v:k for k,v in inv_machine.items()}\n"," \n","    return dataset, human, machine, inv_machine\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stQu_k3xtjaY"},"source":["def load_date():\n","    dt = fake.date_object()\n","\n","    try:\n","        human_readable = format_date(dt, format=random.choice(FORMATS),  locale='en_US')\n","        human_readable = human_readable.lower()\n","        human_readable = human_readable.replace(',','')\n","        machine_readable = dt.isoformat()\n","        \n","    except AttributeError as e:\n","        return None, None, None\n","\n","    return human_readable, machine_readable, dt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N-P6pQZrwT8i"},"source":["def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n","    \n","    X, Y = zip(*dataset)\n","    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n","    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n","    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n","    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n","\n","    return X, np.array(Y), Xoh, Yoh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5i80V7R92gdg"},"source":["def string_to_int(string, length, vocab):\n","    string = string.lower()\n","    string = string.replace(',','')\n","    \n","    if len(string) > length:\n","        string = string[:length]\n","        \n","    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n","    \n","    if len(string) < length:\n","        rep += [vocab['<pad>']] * (length - len(string))\n","    \n","    return rep\n","\n","\n","def int_to_string(ints, inv_vocab):\n","    l = [inv_vocab[i] for i in ints]\n","    return l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hc12wZ_f2wff"},"source":["def softmax(x, axis=1):\n","    ndim = K.ndim(x)\n","    if ndim == 2:\n","        return K.softmax(x)\n","    elif ndim > 2:\n","        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n","        s = K.sum(e, axis=axis, keepdims=True)\n","        return e / s\n","    else:\n","        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n","        \n","\n","def plot_attention_map(model, input_vocabulary, inv_output_vocabulary, text, n_s = 128, num = 6, Tx = 30, Ty = 10):\n","\n","    attention_map = np.zeros((10, 30))\n","    Ty, Tx = attention_map.shape\n","    \n","    s0 = np.zeros((1, n_s))\n","    c0 = np.zeros((1, n_s))\n","    layer = model.layers[num]\n","\n","    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n","    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n","\n","    f = K.function(model.inputs, [layer.get_output_at(t) for t in range(Ty)])\n","    r = f([encoded, s0, c0])\n","    \n","    for t in range(Ty):\n","        for t_prime in range(Tx):\n","            attention_map[t][t_prime] = r[t][0,t_prime,0]\n","\n","    prediction = model.predict([encoded, s0, c0])\n","    \n","    predicted_text = []\n","    for i in range(len(prediction)):\n","        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n","        \n","    predicted_text = list(predicted_text)\n","    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n","    text_ = list(text)\n","\n","    input_length = len(text)\n","    output_length = Ty\n","    \n","    plt.clf()\n","    f = plt.figure(figsize=(8, 8.5))\n","    ax = f.add_subplot(1, 1, 1)\n","\n","    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n","\n","    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n","    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n","    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n","\n","    ax.set_yticks(range(output_length))\n","    ax.set_yticklabels(predicted_text[:output_length])\n","\n","    ax.set_xticks(range(input_length))\n","    ax.set_xticklabels(text_[:input_length], rotation=45)\n","\n","    ax.set_xlabel('Input Sequence')\n","    ax.set_ylabel('Output Sequence')\n","\n","    ax.grid()\n","    \n","    return attention_map"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eOhFdG8Lp5Yr","executionInfo":{"status":"ok","timestamp":1619705654400,"user_tz":240,"elapsed":3007,"user":{"displayName":"Mohammad Siahkamari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh93O-ww1g1fVMNubHBRdJ2afL6y-wMM9gAkLCf43U=s64","userId":"17116706248704947141"}},"outputId":"7ed500f3-191f-4bdf-d30a-db28c80ba288"},"source":["m = 10000\n","dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)\n","dataset[:10]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 10000/10000 [00:00<00:00, 13706.38it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'-': 0,\n"," '0': 1,\n"," '1': 2,\n"," '2': 3,\n"," '3': 4,\n"," '4': 5,\n"," '5': 6,\n"," '6': 7,\n"," '7': 8,\n"," '8': 9,\n"," '9': 10}"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"0ZGWprQJs3xd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619705654901,"user_tz":240,"elapsed":3505,"user":{"displayName":"Mohammad Siahkamari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh93O-ww1g1fVMNubHBRdJ2afL6y-wMM9gAkLCf43U=s64","userId":"17116706248704947141"}},"outputId":"77c0a1f0-3995-4215-fb85-6bbbf4d002fd"},"source":["Tx = 30\n","Ty = 10\n","len(human_vocab)\n","\n","X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n","\n","print(\"X.shape:\", X.shape)\n","print(\"Y.shape:\", Y.shape)\n","print(\"Xoh.shape:\", Xoh.shape)\n","print(\"Yoh.shape:\", Yoh.shape)\n","\n","index = 0\n","print(\"Source date:\", dataset[index][0])\n","print(\"Target date:\", dataset[index][1])\n","print()\n","print(\"Source after preprocessing (indices):\", X[index])\n","print(\"Target after preprocessing (indices):\", Y[index])\n","print()\n","print(\"Source after preprocessing (one-hot):\", Xoh[index])\n","print(\"Target after preprocessing (one-hot):\", Yoh[index])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X.shape: (10000, 30)\n","Y.shape: (10000, 10)\n","Xoh.shape: (10000, 30, 37)\n","Yoh.shape: (10000, 10, 11)\n","Source date: 9 may 1998\n","Target date: 1998-05-09\n","\n","Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n"," 36 36 36 36 36 36]\n","Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n","\n","Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 1.]\n"," [0. 0. 0. ... 0. 0. 1.]]\n","Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-TpeCgb03GBw"},"source":["repeator = RepeatVector(Tx)\n","concatenator = Concatenate(axis=-1)\n","densor1 = Dense(10, activation = \"tanh\")\n","densor2 = Dense(1, activation = \"relu\")\n","activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n","dotor = Dot(axes = 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sC0Qmc3h3UME"},"source":["def one_step_attention(a, s_prev):\n","    s_prev = repeator(s_prev)\n","    concat = concatenator([a, s_prev])\n","    e = densor1(concat)\n","    energies = densor2(e)\n","    alphas = activator(energies)\n","    context = dotor([alphas, a])\n","    return context"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8tp_Goq3diL","executionInfo":{"status":"ok","timestamp":1619705658793,"user_tz":240,"elapsed":7391,"user":{"displayName":"Mohammad Siahkamari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh93O-ww1g1fVMNubHBRdJ2afL6y-wMM9gAkLCf43U=s64","userId":"17116706248704947141"}},"outputId":"ffecb741-946a-4ed8-fbd6-34aa3eeb373d"},"source":["n_a = 32\n","n_s = 64\n","post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n","output_layer = Dense(len(machine_vocab), activation=softmax)\n","\n","def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n","    X = Input(shape=(Tx, human_vocab_size))\n","    s0 = Input(shape=(n_s,), name='s0')\n","    c0 = Input(shape=(n_s,), name='c0')\n","    s = s0\n","    c = c0\n","    outputs = []\n","    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n","    for t in range(Ty):\n","        context = one_step_attention(a, s)\n","        s, _, c = post_activation_LSTM_cell(inputs = context, initial_state= [s, c])\n","        out = output_layer(s)\n","        outputs.append(out)\n","    model = Model(inputs = [X, s0, c0], outputs = outputs)\n","    return model\n","\n","model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 30, 37)]     0                                            \n","__________________________________________________________________________________________________\n","s0 (InputLayer)                 [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","bidirectional (Bidirectional)   (None, 30, 64)       17920       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","repeat_vector (RepeatVector)    (None, 30, 64)       0           s0[0][0]                         \n","                                                                 lstm[0][0]                       \n","                                                                 lstm[1][0]                       \n","                                                                 lstm[2][0]                       \n","                                                                 lstm[3][0]                       \n","                                                                 lstm[4][0]                       \n","                                                                 lstm[5][0]                       \n","                                                                 lstm[6][0]                       \n","                                                                 lstm[7][0]                       \n","                                                                 lstm[8][0]                       \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 30, 128)      0           bidirectional[0][0]              \n","                                                                 repeat_vector[0][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[1][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[2][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[3][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[4][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[5][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[6][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[7][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[8][0]              \n","                                                                 bidirectional[0][0]              \n","                                                                 repeat_vector[9][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 30, 10)       1290        concatenate[0][0]                \n","                                                                 concatenate[1][0]                \n","                                                                 concatenate[2][0]                \n","                                                                 concatenate[3][0]                \n","                                                                 concatenate[4][0]                \n","                                                                 concatenate[5][0]                \n","                                                                 concatenate[6][0]                \n","                                                                 concatenate[7][0]                \n","                                                                 concatenate[8][0]                \n","                                                                 concatenate[9][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 30, 1)        11          dense[0][0]                      \n","                                                                 dense[1][0]                      \n","                                                                 dense[2][0]                      \n","                                                                 dense[3][0]                      \n","                                                                 dense[4][0]                      \n","                                                                 dense[5][0]                      \n","                                                                 dense[6][0]                      \n","                                                                 dense[7][0]                      \n","                                                                 dense[8][0]                      \n","                                                                 dense[9][0]                      \n","__________________________________________________________________________________________________\n","attention_weights (Activation)  (None, 30, 1)        0           dense_1[0][0]                    \n","                                                                 dense_1[1][0]                    \n","                                                                 dense_1[2][0]                    \n","                                                                 dense_1[3][0]                    \n","                                                                 dense_1[4][0]                    \n","                                                                 dense_1[5][0]                    \n","                                                                 dense_1[6][0]                    \n","                                                                 dense_1[7][0]                    \n","                                                                 dense_1[8][0]                    \n","                                                                 dense_1[9][0]                    \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 1, 64)        0           attention_weights[0][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[1][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[2][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[3][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[4][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[5][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[6][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[7][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[8][0]          \n","                                                                 bidirectional[0][0]              \n","                                                                 attention_weights[9][0]          \n","                                                                 bidirectional[0][0]              \n","__________________________________________________________________________________________________\n","c0 (InputLayer)                 [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 64), (None,  33024       dot[0][0]                        \n","                                                                 s0[0][0]                         \n","                                                                 c0[0][0]                         \n","                                                                 dot[1][0]                        \n","                                                                 lstm[0][0]                       \n","                                                                 lstm[0][2]                       \n","                                                                 dot[2][0]                        \n","                                                                 lstm[1][0]                       \n","                                                                 lstm[1][2]                       \n","                                                                 dot[3][0]                        \n","                                                                 lstm[2][0]                       \n","                                                                 lstm[2][2]                       \n","                                                                 dot[4][0]                        \n","                                                                 lstm[3][0]                       \n","                                                                 lstm[3][2]                       \n","                                                                 dot[5][0]                        \n","                                                                 lstm[4][0]                       \n","                                                                 lstm[4][2]                       \n","                                                                 dot[6][0]                        \n","                                                                 lstm[5][0]                       \n","                                                                 lstm[5][2]                       \n","                                                                 dot[7][0]                        \n","                                                                 lstm[6][0]                       \n","                                                                 lstm[6][2]                       \n","                                                                 dot[8][0]                        \n","                                                                 lstm[7][0]                       \n","                                                                 lstm[7][2]                       \n","                                                                 dot[9][0]                        \n","                                                                 lstm[8][0]                       \n","                                                                 lstm[8][2]                       \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 11)           715         lstm[0][0]                       \n","                                                                 lstm[1][0]                       \n","                                                                 lstm[2][0]                       \n","                                                                 lstm[3][0]                       \n","                                                                 lstm[4][0]                       \n","                                                                 lstm[5][0]                       \n","                                                                 lstm[6][0]                       \n","                                                                 lstm[7][0]                       \n","                                                                 lstm[8][0]                       \n","                                                                 lstm[9][0]                       \n","==================================================================================================\n","Total params: 52,960\n","Trainable params: 52,960\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M73at4UGgEx5"},"source":["from keras import optimizers\n","\n","opt = optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wA51UaiMIsCa"},"source":["s0 = np.zeros((m, n_s))\n","c0 = np.zeros((m, n_s))\n","outputs = list(Yoh.swapaxes(0,1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UABHDhby3k16","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89bb24d8-578c-49d6-fb82-1e5f7823c393"},"source":["model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 69/100 [===================>..........] - ETA: 2s - loss: 22.5855 - dense_2_loss: 2.3100 - dense_2_1_loss: 2.2798 - dense_2_2_loss: 2.3834 - dense_2_3_loss: 2.5302 - dense_2_4_loss: 1.8789 - dense_2_5_loss: 2.0296 - dense_2_6_loss: 2.5643 - dense_2_7_loss: 1.7841 - dense_2_8_loss: 2.1471 - dense_2_9_loss: 2.6779 - dense_2_accuracy: 0.1475 - dense_2_1_accuracy: 0.0348 - dense_2_2_accuracy: 0.0536 - dense_2_3_accuracy: 0.0382 - dense_2_4_accuracy: 0.7123 - dense_2_5_accuracy: 0.1064 - dense_2_6_accuracy: 0.0596 - dense_2_7_accuracy: 0.6515 - dense_2_8_accuracy: 0.1058 - dense_2_9_accuracy: 0.0396"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jURR_6nS9F9U"},"source":["model.load_weights('model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kS7KGSoQ3xZZ"},"source":["model.summary()  \n","\n","attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)\n"],"execution_count":null,"outputs":[]}]}